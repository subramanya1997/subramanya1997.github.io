{
  "title": "Pinecone और LLMs के साथ ई-कॉमर्स के लिए हाइब्रिड सर्च",
  "excerpt": "जानें कि पारंपरिक सूचना पुनर्प्राप्ति विधियों को Language Models (LLMs) और Pinecone जैसे मशीन लर्निंग मॉडल के साथ मिलाकर ई-कॉमर्स एप्लिकेशन के लिए एक शक्तिशाली हाइब्रिड सर्च सिस्टम कैसे बनाएं। ई-कॉमर्स के लिए हाइब्रिड सर्च के लाभों की खोज करें, जिसमें बेहतर सर्च प्रासंगिकता, वैयक्तिकरण, लॉन्ग-टेल क्वेरीज़ को संभालना, और सरल इंफ्रास्ट्रक्चर प्रबंधन शामिल हैं।",
  "content_html": "<p>प्रासंगिक उत्पादों को खोजना और ढूंढना एक ई-कॉमर्स वेबसाइट का एक महत्वपूर्ण घटक है। तेज़ और सटीक सर्च परिणाम प्रदान करना उच्च उपयोगकर्ता संतुष्टि और उपयोगकर्ता निराशा के बीच अंतर बना सकता है। प्राकृतिक भाषा समझ और वेक्टर सर्च तकनीकों में हाल की प्रगति के साथ, उन्नत सर्च सिस्टम अधिक सुलभ और कुशल हो गए हैं, जिससे बेहतर उपयोगकर्ता अनुभव और बेहतर रूपांतरण दरें प्राप्त होती हैं।</p>\n\n<p>इस ब्लॉग पोस्ट में, हम Pinecone, एक उच्च-प्रदर्शन वेक्टर सर्च इंजन, और फाइन-ट्यून किए गए डोमेन-विशिष्ट भाषा मॉडल का उपयोग करके ई-कॉमर्स के लिए एक हाइब्रिड सर्च सिस्टम को लागू करने का तरीका जानेंगे। इस पोस्ट के अंत तक, आपको न केवल हाइब्रिड सर्च की मजबूत समझ होगी बल्कि इसे लागू करने के लिए एक व्यावहारिक चरण-दर-चरण गाइड भी मिलेगी।</p>\n\n<h2>हाइब्रिड सर्च क्या है?</h2>\n\n<img src=\"/assets/images/pinecone_hybrid_index.jpg\" alt=\"Pinecone Hybrid Index\" class=\"post-img\" width=\"2360\" height=\"921\" />\n<span class=\"post-img-caption\">सरल Pinecone Hybrid Index का उच्च-स्तरीय दृश्य</span>\n\n<p>कार्यान्वयन में गोता लगाने से पहले, आइए जल्दी से समझें कि हाइब्रिड सर्च का क्या मतलब है। हाइब्रिड सर्च एक दृष्टिकोण है जो पारंपरिक सर्च (sparse vector search) और वेक्टर सर्च (dense vector search) दोनों की ताकत को मिलाकर विभिन्न डोमेन में बेहतर सर्च प्रदर्शन प्राप्त करता है।</p>\n\n<p>Dense vector search टेक्स्ट डेटा से उच्च-गुणवत्ता वाले वेक्टर एम्बेडिंग निकालता है और प्रासंगिक दस्तावेज़ खोजने के लिए समानता सर्च करता है। हालांकि, जब इसे डोमेन-विशिष्ट डेटासेट पर फाइन-ट्यून नहीं किया जाता है तो यह अक्सर आउट-ऑफ-डोमेन डेटा के साथ संघर्ष करता है।</p>\n\n<p>दूसरी ओर, पारंपरिक सर्च sparse vector representations का उपयोग करता है, जैसे term frequency-inverse document frequency (TF-IDF) या BM25, और किसी भी डोमेन-विशिष्ट फाइन-ट्यूनिंग की आवश्यकता नहीं होती है। जबकि यह नए डोमेन को संभाल सकता है, इसका प्रदर्शन शब्दों के बीच शब्दार्थ संबंधों को समझने में असमर्थता से सीमित है और dense retrieval की बुद्धिमत्ता का अभाव है।</p>\n\n<p>हाइब्रिड सर्च दोनों दृष्टिकोणों की कमजोरियों को कम करने का प्रयास करता है, उन्हें एक ही सिस्टम में मिलाकर, dense vector search की प्रदर्शन क्षमता और पारंपरिक सर्च की zero-shot अनुकूलनशीलता का लाभ उठाता है।</p>\n\n<p>अब जब हमें हाइब्रिड सर्च की बुनियादी समझ है, तो आइए इसके कार्यान्वयन में गोता लगाएं।</p>\n\n<h2>हाइब्रिड सर्च सिस्टम बनाना</h2>\n\n<p>हम हाइब्रिड सर्च सिस्टम को लागू करने के लिए निम्नलिखित चरणों को कवर करेंगे:</p>\n\n<ol>\n<li>डोमेन-विशिष्ट भाषा मॉडल का लाभ उठाना</li>\n<li>Sparse और Dense वेक्टर बनाना</li>\n<li>Pinecone सेट अप करना</li>\n<li>हाइब्रिड सर्च पाइपलाइन को लागू करना</li>\n<li>क्वेरीज़ बनाना और पैरामीटर ट्यून करना</li>\n</ol>\n\n<h3>1. डोमेन-विशिष्ट भाषा मॉडल का लाभ उठाना</h3>\n\n<p>हाल के वर्षों में, OpenAI के GPT और Cohere जैसे बड़े पैमाने के पूर्व-प्रशिक्षित भाषा मॉडल प्राकृतिक भाषा समझ और उत्पादन सहित विभिन्न कार्यों के लिए तेजी से लोकप्रिय हो गए हैं। इन मॉडलों को उनके प्रदर्शन में सुधार करने और विशिष्ट कार्यों, जैसे ई-कॉमर्स उत्पाद सर्च, के अनुकूल बनाने के लिए डोमेन-विशिष्ट डेटा पर फाइन-ट्यून किया जा सकता है।</p>\n\n<p>हमारे उदाहरण में, हम उत्पादों और क्वेरीज़ के लिए dense vector embeddings उत्पन्न करने के लिए एक फाइन-ट्यून किए गए डोमेन-विशिष्ट भाषा मॉडल का उपयोग करेंगे। हालांकि, आप अपने विशिष्ट डोमेन के आधार पर अन्य मॉडल चुन सकते हैं या अपने स्वयं के कस्टम एम्बेडिंग भी बना सकते हैं।</p>\n\n<pre><code class=\"language-python\">import torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# Load a pre-trained domain-specific language model\nmodel_name = \"your-domain-specific-model\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\n# Generate dense vector embeddings for a product description\ntext = \"Nike Air Max sports shoes for men\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n    dense_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n</code></pre>\n\n<h3>2. Sparse और Dense वेक्टर बनाना</h3>\n\n<p>हाइब्रिड सर्च को हमारे ई-कॉमर्स डेटा के लिए sparse और dense दोनों वेक्टर representations की आवश्यकता होती है। अब हम वर्णन करेंगे कि इन वेक्टरों को कैसे उत्पन्न किया जाए।</p>\n\n<h4>Sparse Vectors</h4>\n\n<p>Sparse vector representations, जैसे TF-IDF या BM25, मानक टेक्स्ट प्रोसेसिंग तकनीकों का उपयोग करके बनाए जा सकते हैं, जैसे tokenization, stopword removal, और stemming। Sparse vectors उत्पन्न करने का एक उदाहरण vocabulary matrix का उपयोग करके प्राप्त किया जा सकता है।</p>\n\n<pre><code class=\"language-python\"># This function generates sparse vector representations of a list of product descriptions\ndef generate_sparse_vectors(text):\n    '''Generates sparse vector representations for a list of product descriptions\n\n    Args:\n        text (list): A list of product descriptions\n\n    Returns:\n        sparse_vector (dict): A dictionary of indices and values\n    '''\n    sparse_vector = bm25.encode_queries(text)\n    return sparse_vector\n\nfrom pinecone_text.sparse import BM25Encoder\n\n# Create the BM25 encoder and fit the data\nbm25 = BM25Encoder()\nbm25.fit(new_df.full_data)\n\n# Create the sparse vectors\nsparse_vectors = []\nfor product_description in product_descriptions:\n    sparse_vectors.append(generate_sparse_vectors(text=product_description))\n</code></pre>\n\n<h4>Dense Vectors</h4>\n\n<p>Dense vector representations को पूर्व-प्रशिक्षित या कस्टम डोमेन-विशिष्ट भाषा मॉडल का उपयोग करके उत्पन्न किया जा सकता है। हमारे पिछले उदाहरण में, हमने एक उत्पाद विवरण के लिए dense vector embeddings उत्पन्न करने के लिए एक डोमेन-विशिष्ट भाषा मॉडल का उपयोग किया।</p>\n\n<pre><code class=\"language-python\">def generate_dense_vector(text):\n    '''Generates dense vector embeddings for a list of product descriptions\n\n    Args:\n        text (list): A list of product descriptions\n\n    Returns:\n        dense_embedding (np.array): A numpy array of dense vector embeddings\n    '''\n    # Tokenize the text and convert to PyTorch tensors\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    # Generate the embeddings with the pre-trained model\n    with torch.no_grad():\n        outputs = model(**inputs)\n        dense_vector = outputs.last_hidden_state.mean(dim=1).numpy()\n    return dense_vector\n\n# Generate dense vector embeddings for a list of product descriptions\ndense_vectors = []\nfor product_description in product_descriptions:\n    dense_vectors.append(generate_dense_vector(text=product_description))\n</code></pre>\n\n<h3>3. Pinecone सेट अप करना</h3>\n\n<p>Pinecone एक उच्च-प्रदर्शन वेक्टर सर्च इंजन है जो हाइब्रिड सर्च का समर्थन करता है। यह sparse और dense दोनों वेक्टरों के लिए एक एकल इंडेक्स बनाने में सक्षम बनाता है और विभिन्न डेटा modalities में सर्च क्वेरीज़ को सहजता से संभालता है।</p>\n\n<p>Pinecone का उपयोग करने के लिए, आपको एक खाते के लिए साइन अप करना होगा, Pinecone क्लाइंट इंस्टॉल करना होगा, और अपनी API key और environment सेट अप करना होगा।</p>\n\n<pre><code class=\"language-python\"># Create a Pinecone hybrid search index\nimport pinecone\n\npinecone.init(\n    api_key=\"YOUR_API_KEY\",  # app.pinecone.io\n    environment=\"YOUR_ENV\"  # find next to api key in console\n)\n\n# Create a Pinecone hybrid search index\nindex_name = \"ecommerce-hybrid-search\"\npinecone.create_index(\n    index_name = index_name,\n    dimension = MODEL_DIMENSION,  # dimensionality of dense model\n    metric = \"dotproduct\"\n)\n# connect to the index\nindex = pinecone.Index(index_name=index_name)\n# view index stats\nindex.describe_index_stats()\n</code></pre>\n\n<h3>4. हाइब्रिड सर्च पाइपलाइन को लागू करना</h3>\n\n<p>हमारे sparse और dense वेक्टर उत्पन्न होने और Pinecone सेट अप होने के साथ, अब हम एक हाइब्रिड सर्च पाइपलाइन बना सकते हैं। इस पाइपलाइन में निम्नलिखित चरण शामिल हैं:</p>\n\n<ol>\n<li>Pinecone इंडेक्स में उत्पाद डेटा जोड़ना</li>\n<li>Sparse और dense दोनों वेक्टरों का उपयोग करके परिणाम पुनर्प्राप्त करना</li>\n</ol>\n\n<pre><code class=\"language-python\">def add_product_data_to_index(product_ids, sparse_vectors, dense_vectors, metadata=None):\n    \"\"\"Upserts product data to the Pinecone index.\n\n    Args:\n        product_ids (`list` of `str`): Product IDs.\n        sparse_vectors (`list` of `list` of `float`): Sparse vectors.\n        dense_vectors (`list` of `list` of `float`): Dense vectors.\n        metadata (`list` of `list` of `str`): Optional metadata.\n\n    Returns:\n        None\n    \"\"\"\n    batch_size = 32\n\n    # Loop through the product IDs in batches.\n    for i in range(0, len(product_ids), batch_size):\n        i_end = min(i + batch_size, len(product_ids))\n        ids = product_ids[i:i_end]\n        sparse_batch = sparse_vectors[i:i_end]\n        dense_batch = dense_vectors[i:i_end]\n        meta_batch = metadata[i:i_end] if metadata else []\n\n        vectors = []\n        for _id, sparse, dense, meta in zip(ids, sparse_batch, dense_batch, meta_batch):\n            vectors.append({\n                'id': _id,\n                'sparse_values': sparse,\n                'values': dense,\n                'metadata': meta\n            })\n\n        # Upsert the vectors into the Pinecone index.\n        index.upsert(vectors=vectors)\n\nadd_product_data_to_index(product_ids, sparse_vectors, dense_vectors)\n</code></pre>\n\n<p>अब जब हमारा डेटा इंडेक्स हो गया है, हम हाइब्रिड सर्च क्वेरीज़ कर सकते हैं।</p>\n\n<h3>5. क्वेरीज़ बनाना और पैरामीटर ट्यून करना</h3>\n\n<img src=\"/assets/images/pinecone_hybrid_query.jpg\" alt=\"Pinecone Hybrid Query\" class=\"post-img\" width=\"2360\" height=\"892\" />\n<span class=\"post-img-caption\">सरल Pinecone Hybrid Query का उच्च-स्तरीय दृश्य</span>\n\n<p>हाइब्रिड सर्च क्वेरीज़ बनाने के लिए, हम एक फ़ंक्शन बनाएंगे जो एक क्वेरी, शीर्ष परिणामों की संख्या, और dense और sparse vector search स्कोर के बीच वेटिंग को नियंत्रित करने के लिए एक alpha पैरामीटर लेता है।</p>\n\n<pre><code class=\"language-python\">def hybrid_scale(dense, sparse, alpha: float):\n    \"\"\"Hybrid vector scaling using a convex combination\n\n    alpha * dense + (1 - alpha) * sparse\n\n    Args:\n        dense: Array of floats representing\n        sparse: a dict of `indices` and `values`\n        alpha: float between 0 and 1 where 0 == sparse only\n               and 1 == dense only\n    \"\"\"\n    if alpha &lt; 0 or alpha &gt; 1:\n        raise ValueError(\"Alpha must be between 0 and 1\")\n    # scale sparse and dense vectors to create hybrid search vecs\n    hsparse = {\n        'indices': sparse['indices'],\n        'values':  [v * (1 - alpha) for v in sparse['values']]\n    }\n    hdense = [v * alpha for v in dense]\n    return hdense, hsparse\n\ndef search_products(query, top_k=10, alpha=0.5):\n    # Generate sparse query vector\n    sparse_query_vector = generate_sparse_vector(query)\n\n    # Generate dense query vector\n    dense_query_vector = generate_dense_vector(query)\n\n    # Calculate hybrid query vector\n    dense_query_vector, sparse_query_vector = hybrid_scale(dense_query_vector, sparse_query_vector, alpha)\n\n    # Search products using Pinecone\n    results = index.query(\n        vector=dense_query_vector,\n        sparse_vector=sparse_query_vector,\n        top_k=top_k\n    )\n\n    return results\n</code></pre>\n\n<p>फिर हम इस फ़ंक्शन का उपयोग अपने ई-कॉमर्स डेटासेट में प्रासंगिक उत्पादों को खोजने के लिए कर सकते हैं।</p>\n\n<pre><code class=\"language-python\">query = \"running shoes for women\"\nresults = search_products(query, top_k=5)\n\nfor result in results:\n    print(result['id'], result['metadata']['product_name'], result['score'])\n</code></pre>\n\n<p>Alpha पैरामीटर के लिए विभिन्न मानों के साथ प्रयोग करने से आपको अपने विशिष्ट डोमेन के लिए sparse और dense vector search के बीच इष्टतम संतुलन खोजने में मदद मिलेगी।</p>\n\n<h2>निष्कर्ष</h2>\n\n<p>इस ब्लॉग पोस्ट में, हमने Pinecone और डोमेन-विशिष्ट भाषा मॉडल का उपयोग करके ई-कॉमर्स के लिए एक हाइब्रिड सर्च सिस्टम बनाने का तरीका प्रदर्शित किया। हाइब्रिड सर्च हमें पारंपरिक सर्च और वेक्टर सर्च दोनों की ताकत को मिलाने में सक्षम बनाता है, जिससे विविध डोमेन में सर्च प्रदर्शन और अनुकूलनशीलता में सुधार होता है।</p>\n\n<p>इस पोस्ट में दिए गए चरणों और कोड स्निपेट का पालन करके, आप अपनी ई-कॉमर्स वेबसाइट की विशिष्ट आवश्यकताओं के अनुरूप अपना स्वयं का हाइब्रिड सर्च सिस्टम लागू कर सकते हैं। Pinecone की खोज शुरू करें और आज ही अपने ई-कॉमर्स सर्च अनुभव में सुधार करें!</p>\n\n<h2>संदर्भ</h2>\n\n<ul>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/search/hybrid-search/ecommerce-search/ecommerce-search.ipynb\">Ecommerce Search using Hybrid Search Techniques in Pinecone (Google Colab Notebook)</a>: Pinecone की हाइब्रिड सर्च तकनीकों का उपयोग करके ई-कॉमर्स सर्च के कार्यान्वयन को प्रदर्शित करने वाली एक व्यावहारिक गाइड।</li>\n<li><a href=\"https://docs.pinecone.io/docs/ecommerce-search\">Pinecone Ecommerce Search Documentation</a>: ई-कॉमर्स सर्च सिस्टम बनाने के लिए आधिकारिक Pinecone दस्तावेज़ीकरण।</li>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/pinecone/sparse/bm25/bm25-vector-generation.ipynb\">BM25 Vector Generation using Pinecone (Google Colab Notebook)</a>: Pinecone का उपयोग करके BM25 sparse vectors उत्पन्न करने के लिए एक गाइड।</li>\n<li><a href=\"https://github.com/pinecone-io/pinecone-text\">Pinecone Text Repository on GitHub</a>: Pinecone का उपयोग करके टेक्स्ट प्रोसेसिंग और वेक्टर जनरेशन संसाधनों का एक संग्रह।</li>\n<li><a href=\"https://www.pinecone.io/learn/hybrid-search-intro/\">Introduction to Hybrid Search on Pinecone's Website</a>: Pinecone की क्षमताओं के संदर्भ में हाइब्रिड सर्च, इसके लाभ और उपयोग के मामलों का एक अवलोकन।</li>\n</ul>",
  "source_hash": "sha256:c8b3789c888127b9f8404365e651e80624c4177f346d2aef54a3b185e2cd138b",
  "model": "claude-sonnet-4-5-20250929",
  "generated_at": "2026-01-15T20:04:48.585141+00:00"
}