{
  "title": "Recherche hybride pour l'e-commerce avec Pinecone et les LLM",
  "excerpt": "Apprenez à construire un système de recherche hybride puissant pour les applications e-commerce en combinant les méthodes traditionnelles de recherche d'information avec des modèles d'apprentissage automatique comme les modèles de langage (LLM) et Pinecone, une base de données vectorielle gérée. Découvrez les avantages de la recherche hybride pour l'e-commerce, notamment l'amélioration de la pertinence de recherche, la personnalisation, la gestion des requêtes de longue traîne et une gestion d'infrastructure simplifiée.",
  "content_html": "<p>La recherche et la découverte de produits pertinents constituent un élément essentiel d'un site e-commerce. Fournir des résultats de recherche rapides et précis peut faire la différence entre une grande satisfaction utilisateur et une frustration. Avec les récentes avancées en compréhension du langage naturel et en technologies de recherche vectorielle, les systèmes de recherche améliorés sont devenus plus accessibles et efficaces, conduisant à de meilleures expériences utilisateur et à des taux de conversion améliorés.</p>\n\n<p>Dans cet article de blog, nous explorerons comment implémenter un système de recherche hybride pour l'e-commerce en utilisant Pinecone, un moteur de recherche vectorielle haute performance, et des modèles de langage spécifiques au domaine finement ajustés. À la fin de cet article, vous aurez non seulement une solide compréhension de la recherche hybride, mais aussi un guide pratique étape par étape pour l'implémenter.</p>\n\n<h2>Qu'est-ce que la recherche hybride ?</h2>\n\n<img src=\"/assets/images/pinecone_hybrid_index.jpg\" alt=\"Pinecone Hybrid Index\" class=\"post-img\" width=\"2360\" height=\"921\" />\n<span class=\"post-img-caption\">Vue de haut niveau d'un index hybride Pinecone simple</span>\n\n<p>Avant de plonger dans l'implémentation, comprenons rapidement ce que signifie la recherche hybride. La recherche hybride est une approche qui combine les forces de la recherche traditionnelle (recherche vectorielle sparse) et de la recherche vectorielle (recherche vectorielle dense) pour obtenir de meilleures performances de recherche dans un large éventail de domaines.</p>\n\n<p>La recherche vectorielle dense extrait des embeddings vectoriels de haute qualité à partir de données textuelles et effectue une recherche de similarité pour trouver des documents pertinents. Cependant, elle a souvent du mal avec les données hors domaine lorsqu'elle n'est pas finement ajustée sur des ensembles de données spécifiques au domaine.</p>\n\n<p>D'autre part, la recherche traditionnelle utilise des représentations vectorielles sparse, comme la fréquence des termes-fréquence inverse des documents (TF-IDF) ou BM25, et ne nécessite aucun ajustement spécifique au domaine. Bien qu'elle puisse gérer de nouveaux domaines, ses performances sont limitées par son incapacité à comprendre les relations sémantiques entre les mots et manque de l'intelligence de la récupération dense.</p>\n\n<p>La recherche hybride tente d'atténuer les faiblesses des deux approches en les combinant dans un système unique, tirant parti du potentiel de performance de la recherche vectorielle dense et de l'adaptabilité zero-shot de la recherche traditionnelle.</p>\n\n<p>Maintenant que nous avons une compréhension de base de la recherche hybride, plongeons dans son implémentation.</p>\n\n<h2>Construire un système de recherche hybride</h2>\n\n<p>Nous couvrirons les étapes suivantes pour implémenter un système de recherche hybride :</p>\n\n<ol>\n<li>Exploiter les modèles de langage spécifiques au domaine</li>\n<li>Créer des vecteurs sparse et dense</li>\n<li>Configurer Pinecone</li>\n<li>Implémenter le pipeline de recherche hybride</li>\n<li>Effectuer des requêtes et ajuster les paramètres</li>\n</ol>\n\n<h3>1. Exploiter les modèles de langage spécifiques au domaine</h3>\n\n<p>Ces dernières années, les modèles de langage pré-entraînés à grande échelle comme GPT d'OpenAI et Cohere sont devenus de plus en plus populaires pour une variété de tâches, notamment la compréhension et la génération du langage naturel. Ces modèles peuvent être finement ajustés sur des données spécifiques au domaine pour améliorer leurs performances et s'adapter à des tâches spécifiques, telles que la recherche de produits e-commerce.</p>\n\n<p>Dans notre exemple, nous utiliserons un modèle de langage spécifique au domaine finement ajusté pour générer des embeddings vectoriels denses pour les produits et les requêtes. Cependant, vous pouvez choisir d'autres modèles ou même créer vos propres embeddings personnalisés en fonction de votre domaine spécifique.</p>\n\n<pre><code class=\"language-python\">import torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# Load a pre-trained domain-specific language model\nmodel_name = \"your-domain-specific-model\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\n# Generate dense vector embeddings for a product description\ntext = \"Nike Air Max sports shoes for men\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n    dense_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n</code></pre>\n\n<h3>2. Créer des vecteurs sparse et dense</h3>\n\n<p>La recherche hybride nécessite à la fois des représentations vectorielles sparse et dense pour nos données e-commerce. Nous allons maintenant décrire comment générer ces vecteurs.</p>\n\n<h4>Vecteurs sparse</h4>\n\n<p>Les représentations vectorielles sparse, comme TF-IDF ou BM25, peuvent être créées en utilisant des techniques standard de traitement de texte, telles que la tokenisation, la suppression des mots vides et la lemmatisation. Un exemple de génération de vecteurs sparse peut être réalisé en utilisant une matrice de vocabulaire.</p>\n\n<pre><code class=\"language-python\"># This function generates sparse vector representations of a list of product descriptions\ndef generate_sparse_vectors(text):\n    '''Generates sparse vector representations for a list of product descriptions\n\n    Args:\n        text (list): A list of product descriptions\n\n    Returns:\n        sparse_vector (dict): A dictionary of indices and values\n    '''\n    sparse_vector = bm25.encode_queries(text)\n    return sparse_vector\n\nfrom pinecone_text.sparse import BM25Encoder\n\n# Create the BM25 encoder and fit the data\nbm25 = BM25Encoder()\nbm25.fit(new_df.full_data)\n\n# Create the sparse vectors\nsparse_vectors = []\nfor product_description in product_descriptions:\n    sparse_vectors.append(generate_sparse_vectors(text=product_description))\n</code></pre>\n\n<h4>Vecteurs dense</h4>\n\n<p>Les représentations vectorielles denses peuvent être générées en utilisant des modèles de langage pré-entraînés ou personnalisés spécifiques au domaine. Dans notre exemple précédent, nous avons utilisé un modèle de langage spécifique au domaine pour générer des embeddings vectoriels denses pour une description de produit.</p>\n\n<pre><code class=\"language-python\">def generate_dense_vector(text):\n    '''Generates dense vector embeddings for a list of product descriptions\n\n    Args:\n        text (list): A list of product descriptions\n\n    Returns:\n        dense_embedding (np.array): A numpy array of dense vector embeddings\n    '''\n    # Tokenize the text and convert to PyTorch tensors\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    # Generate the embeddings with the pre-trained model\n    with torch.no_grad():\n        outputs = model(**inputs)\n        dense_vector = outputs.last_hidden_state.mean(dim=1).numpy()\n    return dense_vector\n\n# Generate dense vector embeddings for a list of product descriptions\ndense_vectors = []\nfor product_description in product_descriptions:\n    dense_vectors.append(generate_dense_vector(text=product_description))\n</code></pre>\n\n<h3>3. Configurer Pinecone</h3>\n\n<p>Pinecone est un moteur de recherche vectorielle haute performance qui prend en charge la recherche hybride. Il permet la création d'un index unique pour les vecteurs sparse et dense et gère de manière transparente les requêtes de recherche sur différentes modalités de données.</p>\n\n<p>Pour utiliser Pinecone, vous devrez créer un compte, installer le client Pinecone et configurer votre clé API et votre environnement.</p>\n\n<pre><code class=\"language-python\"># Create a Pinecone hybrid search index\nimport pinecone\n\npinecone.init(\n    api_key=\"YOUR_API_KEY\",  # app.pinecone.io\n    environment=\"YOUR_ENV\"  # find next to api key in console\n)\n\n# Create a Pinecone hybrid search index\nindex_name = \"ecommerce-hybrid-search\"\npinecone.create_index(\n    index_name = index_name,\n    dimension = MODEL_DIMENSION,  # dimensionality of dense model\n    metric = \"dotproduct\"\n)\n# connect to the index\nindex = pinecone.Index(index_name=index_name)\n# view index stats\nindex.describe_index_stats()\n</code></pre>\n\n<h3>4. Implémenter le pipeline de recherche hybride</h3>\n\n<p>Avec nos vecteurs sparse et dense générés et Pinecone configuré, nous pouvons maintenant construire un pipeline de recherche hybride. Ce pipeline comprend les étapes suivantes :</p>\n\n<ol>\n<li>Ajouter les données de produits à l'index Pinecone</li>\n<li>Récupérer les résultats en utilisant à la fois les vecteurs sparse et dense</li>\n</ol>\n\n<pre><code class=\"language-python\">def add_product_data_to_index(product_ids, sparse_vectors, dense_vectors, metadata=None):\n    \"\"\"Upserts product data to the Pinecone index.\n\n    Args:\n        product_ids (`list` of `str`): Product IDs.\n        sparse_vectors (`list` of `list` of `float`): Sparse vectors.\n        dense_vectors (`list` of `list` of `float`): Dense vectors.\n        metadata (`list` of `list` of `str`): Optional metadata.\n\n    Returns:\n        None\n    \"\"\"\n    batch_size = 32\n\n    # Loop through the product IDs in batches.\n    for i in range(0, len(product_ids), batch_size):\n        i_end = min(i + batch_size, len(product_ids))\n        ids = product_ids[i:i_end]\n        sparse_batch = sparse_vectors[i:i_end]\n        dense_batch = dense_vectors[i:i_end]\n        meta_batch = metadata[i:i_end] if metadata else []\n\n        vectors = []\n        for _id, sparse, dense, meta in zip(ids, sparse_batch, dense_batch, meta_batch):\n            vectors.append({\n                'id': _id,\n                'sparse_values': sparse,\n                'values': dense,\n                'metadata': meta\n            })\n\n        # Upsert the vectors into the Pinecone index.\n        index.upsert(vectors=vectors)\n\nadd_product_data_to_index(product_ids, sparse_vectors, dense_vectors)\n</code></pre>\n\n<p>Maintenant que nos données sont indexées, nous pouvons effectuer des requêtes de recherche hybride.</p>\n\n<h3>5. Effectuer des requêtes et ajuster les paramètres</h3>\n\n<img src=\"/assets/images/pinecone_hybrid_query.jpg\" alt=\"Pinecone Hybrid Query\" class=\"post-img\" width=\"2360\" height=\"892\" />\n<span class=\"post-img-caption\">Vue de haut niveau d'une requête hybride Pinecone simple</span>\n\n<p>Pour effectuer des requêtes de recherche hybride, nous allons créer une fonction qui prend une requête, le nombre de meilleurs résultats et un paramètre alpha pour contrôler la pondération entre les scores de recherche vectorielle dense et sparse.</p>\n\n<pre><code class=\"language-python\">def hybrid_scale(dense, sparse, alpha: float):\n    \"\"\"Hybrid vector scaling using a convex combination\n\n    alpha * dense + (1 - alpha) * sparse\n\n    Args:\n        dense: Array of floats representing\n        sparse: a dict of `indices` and `values`\n        alpha: float between 0 and 1 where 0 == sparse only\n               and 1 == dense only\n    \"\"\"\n    if alpha &lt; 0 or alpha &gt; 1:\n        raise ValueError(\"Alpha must be between 0 and 1\")\n    # scale sparse and dense vectors to create hybrid search vecs\n    hsparse = {\n        'indices': sparse['indices'],\n        'values':  [v * (1 - alpha) for v in sparse['values']]\n    }\n    hdense = [v * alpha for v in dense]\n    return hdense, hsparse\n\ndef search_products(query, top_k=10, alpha=0.5):\n    # Generate sparse query vector\n    sparse_query_vector = generate_sparse_vector(query)\n\n    # Generate dense query vector\n    dense_query_vector = generate_dense_vector(query)\n\n    # Calculate hybrid query vector\n    dense_query_vector, sparse_query_vector = hybrid_scale(dense_query_vector, sparse_query_vector, alpha)\n\n    # Search products using Pinecone\n    results = index.query(\n        vector=dense_query_vector,\n        sparse_vector=sparse_query_vector,\n        top_k=top_k\n    )\n\n    return results\n</code></pre>\n\n<p>Nous pouvons ensuite utiliser cette fonction pour rechercher des produits pertinents dans notre ensemble de données e-commerce.</p>\n\n<pre><code class=\"language-python\">query = \"running shoes for women\"\nresults = search_products(query, top_k=5)\n\nfor result in results:\n    print(result['id'], result['metadata']['product_name'], result['score'])\n</code></pre>\n\n<p>Expérimenter avec différentes valeurs pour le paramètre alpha vous aidera à trouver l'équilibre optimal entre la recherche vectorielle sparse et dense pour votre domaine spécifique.</p>\n\n<h2>Conclusion</h2>\n\n<p>Dans cet article de blog, nous avons démontré comment construire un système de recherche hybride pour l'e-commerce en utilisant Pinecone et des modèles de langage spécifiques au domaine. La recherche hybride nous permet de combiner les forces de la recherche traditionnelle et de la recherche vectorielle, améliorant les performances de recherche et l'adaptabilité dans divers domaines.</p>\n\n<p>En suivant les étapes et les extraits de code fournis dans cet article, vous pouvez implémenter votre propre système de recherche hybride adapté aux exigences spécifiques de votre site e-commerce. Commencez à explorer Pinecone et améliorez votre expérience de recherche e-commerce dès aujourd'hui !</p>\n\n<h2>Références</h2>\n\n<ul>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/search/hybrid-search/ecommerce-search/ecommerce-search.ipynb\">Ecommerce Search using Hybrid Search Techniques in Pinecone (Google Colab Notebook)</a> : Un guide pratique présentant l'implémentation de la recherche e-commerce en utilisant les techniques de recherche hybride de Pinecone.</li>\n<li><a href=\"https://docs.pinecone.io/docs/ecommerce-search\">Pinecone Ecommerce Search Documentation</a> : Documentation officielle de Pinecone pour la construction de systèmes de recherche e-commerce.</li>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/pinecone/sparse/bm25/bm25-vector-generation.ipynb\">BM25 Vector Generation using Pinecone (Google Colab Notebook)</a> : Un guide pour générer des vecteurs sparse BM25 en utilisant Pinecone.</li>\n<li><a href=\"https://github.com/pinecone-io/pinecone-text\">Pinecone Text Repository on GitHub</a> : Une collection de ressources de traitement de texte et de génération de vecteurs utilisant Pinecone.</li>\n<li><a href=\"https://www.pinecone.io/learn/hybrid-search-intro/\">Introduction to Hybrid Search on Pinecone's Website</a> : Un aperçu de la recherche hybride, de ses avantages et de ses cas d'utilisation dans le contexte des capacités de Pinecone.</li>\n</ul>",
  "source_hash": "sha256:c8b3789c888127b9f8404365e651e80624c4177f346d2aef54a3b185e2cd138b",
  "model": "claude-sonnet-4-5-20250929",
  "generated_at": "2026-01-15T20:04:18.726355+00:00"
}