{
  "title": "Búsqueda Híbrida para E-Commerce con Pinecone y LLMs",
  "excerpt": "Aprende cómo construir un potente sistema de búsqueda híbrida para aplicaciones de comercio electrónico combinando métodos tradicionales de recuperación de información con modelos de aprendizaje automático como Modelos de Lenguaje (LLMs) y Pinecone, una base de datos vectorial administrada. Descubre los beneficios de la búsqueda híbrida para e-commerce, incluyendo relevancia de búsqueda mejorada, personalización, manejo de consultas de cola larga y gestión de infraestructura más simple.",
  "content_html": "<p>Buscar y encontrar productos relevantes es un componente crítico de un sitio web de comercio electrónico. Proporcionar resultados de búsqueda rápidos y precisos puede marcar la diferencia entre una alta satisfacción del usuario y la frustración del usuario. Con los recientes avances en comprensión del lenguaje natural y tecnologías de búsqueda vectorial, los sistemas de búsqueda mejorados se han vuelto más accesibles y eficientes, lo que conduce a mejores experiencias de usuario y tasas de conversión mejoradas.</p>\n\n<p>En esta publicación de blog, exploraremos cómo implementar un sistema de búsqueda híbrida para comercio electrónico utilizando Pinecone, un motor de búsqueda vectorial de alto rendimiento, y modelos de lenguaje específicos de dominio ajustados. Al final de esta publicación, no solo tendrás una sólida comprensión de la búsqueda híbrida, sino también una guía práctica paso a paso para implementarla.</p>\n\n<h2>¿Qué es la Búsqueda Híbrida?</h2>\n\n<img src=\"/assets/images/pinecone_hybrid_index.jpg\" alt=\"Pinecone Hybrid Index\" class=\"post-img\" width=\"2360\" height=\"921\" />\n<span class=\"post-img-caption\">Vista de alto nivel de un índice híbrido simple de Pinecone</span>\n\n<p>Antes de sumergirnos en la implementación, entendamos rápidamente qué significa búsqueda híbrida. La búsqueda híbrida es un enfoque que combina las fortalezas tanto de la búsqueda tradicional (búsqueda de vectores dispersos) como de la búsqueda vectorial (búsqueda de vectores densos) para lograr un mejor rendimiento de búsqueda en una amplia gama de dominios.</p>\n\n<p>La búsqueda de vectores densos extrae embeddings vectoriales de alta calidad de datos de texto y realiza una búsqueda de similitud para encontrar documentos relevantes. Sin embargo, a menudo tiene dificultades con datos fuera del dominio cuando no está ajustada en conjuntos de datos específicos del dominio.</p>\n\n<p>Por otro lado, la búsqueda tradicional utiliza representaciones vectoriales dispersas, como la frecuencia de términos-frecuencia inversa de documentos (TF-IDF) o BM25, y no requiere ningún ajuste específico del dominio. Si bien puede manejar nuevos dominios, su rendimiento está limitado por su incapacidad para comprender las relaciones semánticas entre palabras y carece de la inteligencia de la recuperación densa.</p>\n\n<p>La búsqueda híbrida intenta mitigar las debilidades de ambos enfoques combinándolos en un solo sistema, aprovechando el potencial de rendimiento de la búsqueda de vectores densos y la adaptabilidad zero-shot de la búsqueda tradicional.</p>\n\n<p>Ahora que tenemos una comprensión básica de la búsqueda híbrida, sumerjámonos en su implementación.</p>\n\n<h2>Construyendo un Sistema de Búsqueda Híbrida</h2>\n\n<p>Cubriremos los siguientes pasos para implementar un sistema de búsqueda híbrida:</p>\n\n<ol>\n<li>Aprovechando Modelos de Lenguaje Específicos de Dominio</li>\n<li>Creando Vectores Dispersos y Densos</li>\n<li>Configurando Pinecone</li>\n<li>Implementando el Pipeline de Búsqueda Híbrida</li>\n<li>Realizando Consultas y Ajustando Parámetros</li>\n</ol>\n\n<h3>1. Aprovechando Modelos de Lenguaje Específicos de Dominio</h3>\n\n<p>En los últimos años, los modelos de lenguaje preentrenados a gran escala como GPT de OpenAI y Cohere se han vuelto cada vez más populares para una variedad de tareas, incluyendo la comprensión y generación del lenguaje natural. Estos modelos pueden ser ajustados en datos específicos del dominio para mejorar su rendimiento y adaptarse a tareas específicas, como la búsqueda de productos de comercio electrónico.</p>\n\n<p>En nuestro ejemplo, utilizaremos un modelo de lenguaje específico de dominio ajustado para generar embeddings vectoriales densos para productos y consultas. Sin embargo, puedes elegir otros modelos o incluso crear tus propios embeddings personalizados basados en tu dominio específico.</p>\n\n<pre><code class=\"language-python\">import torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# Load a pre-trained domain-specific language model\nmodel_name = \"your-domain-specific-model\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\n# Generate dense vector embeddings for a product description\ntext = \"Nike Air Max sports shoes for men\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n    dense_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n</code></pre>\n\n<h3>2. Creando Vectores Dispersos y Densos</h3>\n\n<p>La búsqueda híbrida requiere representaciones vectoriales tanto dispersas como densas para nuestros datos de comercio electrónico. Ahora describiremos cómo generar estos vectores.</p>\n\n<h4>Vectores Dispersos</h4>\n\n<p>Las representaciones vectoriales dispersas, como TF-IDF o BM25, se pueden crear utilizando técnicas estándar de procesamiento de texto, como tokenización, eliminación de palabras vacías y lematización. Un ejemplo de generación de vectores dispersos se puede lograr utilizando una matriz de vocabulario.</p>\n\n<pre><code class=\"language-python\"># This function generates sparse vector representations of a list of product descriptions\ndef generate_sparse_vectors(text):\n    '''Generates sparse vector representations for a list of product descriptions\n\n    Args:\n        text (list): A list of product descriptions\n\n    Returns:\n        sparse_vector (dict): A dictionary of indices and values\n    '''\n    sparse_vector = bm25.encode_queries(text)\n    return sparse_vector\n\nfrom pinecone_text.sparse import BM25Encoder\n\n# Create the BM25 encoder and fit the data\nbm25 = BM25Encoder()\nbm25.fit(new_df.full_data)\n\n# Create the sparse vectors\nsparse_vectors = []\nfor product_description in product_descriptions:\n    sparse_vectors.append(generate_sparse_vectors(text=product_description))\n</code></pre>\n\n<h4>Vectores Densos</h4>\n\n<p>Las representaciones vectoriales densas se pueden generar utilizando modelos de lenguaje preentrenados o personalizados específicos del dominio. En nuestro ejemplo anterior, utilizamos un modelo de lenguaje específico de dominio para generar embeddings vectoriales densos para una descripción de producto.</p>\n\n<pre><code class=\"language-python\">def generate_dense_vector(text):\n    '''Generates dense vector embeddings for a list of product descriptions\n\n    Args:\n        text (list): A list of product descriptions\n\n    Returns:\n        dense_embedding (np.array): A numpy array of dense vector embeddings\n    '''\n    # Tokenize the text and convert to PyTorch tensors\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    # Generate the embeddings with the pre-trained model\n    with torch.no_grad():\n        outputs = model(**inputs)\n        dense_vector = outputs.last_hidden_state.mean(dim=1).numpy()\n    return dense_vector\n\n# Generate dense vector embeddings for a list of product descriptions\ndense_vectors = []\nfor product_description in product_descriptions:\n    dense_vectors.append(generate_dense_vector(text=product_description))\n</code></pre>\n\n<h3>3. Configurando Pinecone</h3>\n\n<p>Pinecone es un motor de búsqueda vectorial de alto rendimiento que admite búsqueda híbrida. Permite la creación de un índice único para vectores dispersos y densos y maneja sin problemas las consultas de búsqueda en diferentes modalidades de datos.</p>\n\n<p>Para usar Pinecone, necesitarás registrarte para obtener una cuenta, instalar el cliente de Pinecone y configurar tu clave API y entorno.</p>\n\n<pre><code class=\"language-python\"># Create a Pinecone hybrid search index\nimport pinecone\n\npinecone.init(\n    api_key=\"YOUR_API_KEY\",  # app.pinecone.io\n    environment=\"YOUR_ENV\"  # find next to api key in console\n)\n\n# Create a Pinecone hybrid search index\nindex_name = \"ecommerce-hybrid-search\"\npinecone.create_index(\n    index_name = index_name,\n    dimension = MODEL_DIMENSION,  # dimensionality of dense model\n    metric = \"dotproduct\"\n)\n# connect to the index\nindex = pinecone.Index(index_name=index_name)\n# view index stats\nindex.describe_index_stats()\n</code></pre>\n\n<h3>4. Implementando el Pipeline de Búsqueda Híbrida</h3>\n\n<p>Con nuestros vectores dispersos y densos generados y Pinecone configurado, ahora podemos construir un pipeline de búsqueda híbrida. Este pipeline incluye los siguientes pasos:</p>\n\n<ol>\n<li>Agregar datos de productos al índice de Pinecone</li>\n<li>Recuperar resultados utilizando vectores dispersos y densos</li>\n</ol>\n\n<pre><code class=\"language-python\">def add_product_data_to_index(product_ids, sparse_vectors, dense_vectors, metadata=None):\n    \"\"\"Upserts product data to the Pinecone index.\n\n    Args:\n        product_ids (`list` of `str`): Product IDs.\n        sparse_vectors (`list` of `list` of `float`): Sparse vectors.\n        dense_vectors (`list` of `list` of `float`): Dense vectors.\n        metadata (`list` of `list` of `str`): Optional metadata.\n\n    Returns:\n        None\n    \"\"\"\n    batch_size = 32\n\n    # Loop through the product IDs in batches.\n    for i in range(0, len(product_ids), batch_size):\n        i_end = min(i + batch_size, len(product_ids))\n        ids = product_ids[i:i_end]\n        sparse_batch = sparse_vectors[i:i_end]\n        dense_batch = dense_vectors[i:i_end]\n        meta_batch = metadata[i:i_end] if metadata else []\n\n        vectors = []\n        for _id, sparse, dense, meta in zip(ids, sparse_batch, dense_batch, meta_batch):\n            vectors.append({\n                'id': _id,\n                'sparse_values': sparse,\n                'values': dense,\n                'metadata': meta\n            })\n\n        # Upsert the vectors into the Pinecone index.\n        index.upsert(vectors=vectors)\n\nadd_product_data_to_index(product_ids, sparse_vectors, dense_vectors)\n</code></pre>\n\n<p>Ahora que nuestros datos están indexados, podemos realizar consultas de búsqueda híbrida.</p>\n\n<h3>5. Realizando Consultas y Ajustando Parámetros</h3>\n\n<img src=\"/assets/images/pinecone_hybrid_query.jpg\" alt=\"Pinecone Hybrid Query\" class=\"post-img\" width=\"2360\" height=\"892\" />\n<span class=\"post-img-caption\">Vista de alto nivel de una consulta híbrida simple de Pinecone</span>\n\n<p>Para realizar consultas de búsqueda híbrida, crearemos una función que tome una consulta, el número de resultados principales y un parámetro alpha para controlar la ponderación entre las puntuaciones de búsqueda de vectores densos y dispersos.</p>\n\n<pre><code class=\"language-python\">def hybrid_scale(dense, sparse, alpha: float):\n    \"\"\"Hybrid vector scaling using a convex combination\n\n    alpha * dense + (1 - alpha) * sparse\n\n    Args:\n        dense: Array of floats representing\n        sparse: a dict of `indices` and `values`\n        alpha: float between 0 and 1 where 0 == sparse only\n               and 1 == dense only\n    \"\"\"\n    if alpha &lt; 0 or alpha &gt; 1:\n        raise ValueError(\"Alpha must be between 0 and 1\")\n    # scale sparse and dense vectors to create hybrid search vecs\n    hsparse = {\n        'indices': sparse['indices'],\n        'values':  [v * (1 - alpha) for v in sparse['values']]\n    }\n    hdense = [v * alpha for v in dense]\n    return hdense, hsparse\n\ndef search_products(query, top_k=10, alpha=0.5):\n    # Generate sparse query vector\n    sparse_query_vector = generate_sparse_vector(query)\n\n    # Generate dense query vector\n    dense_query_vector = generate_dense_vector(query)\n\n    # Calculate hybrid query vector\n    dense_query_vector, sparse_query_vector = hybrid_scale(dense_query_vector, sparse_query_vector, alpha)\n\n    # Search products using Pinecone\n    results = index.query(\n        vector=dense_query_vector,\n        sparse_vector=sparse_query_vector,\n        top_k=top_k\n    )\n\n    return results\n</code></pre>\n\n<p>Luego podemos usar esta función para buscar productos relevantes en nuestro conjunto de datos de comercio electrónico.</p>\n\n<pre><code class=\"language-python\">query = \"running shoes for women\"\nresults = search_products(query, top_k=5)\n\nfor result in results:\n    print(result['id'], result['metadata']['product_name'], result['score'])\n</code></pre>\n\n<p>Experimentar con diferentes valores para el parámetro alpha te ayudará a encontrar el equilibrio óptimo entre la búsqueda de vectores dispersos y densos para tu dominio específico.</p>\n\n<h2>Conclusión</h2>\n\n<p>En esta publicación de blog, demostramos cómo construir un sistema de búsqueda híbrida para comercio electrónico utilizando Pinecone y modelos de lenguaje específicos de dominio. La búsqueda híbrida nos permite combinar las fortalezas tanto de la búsqueda tradicional como de la búsqueda vectorial, mejorando el rendimiento de búsqueda y la adaptabilidad en diversos dominios.</p>\n\n<p>Siguiendo los pasos y fragmentos de código proporcionados en esta publicación, puedes implementar tu propio sistema de búsqueda híbrida adaptado a los requisitos específicos de tu sitio web de comercio electrónico. ¡Comienza a explorar Pinecone y mejora tu experiencia de búsqueda de comercio electrónico hoy!</p>\n\n<h2>Referencias</h2>\n\n<ul>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/search/hybrid-search/ecommerce-search/ecommerce-search.ipynb\">Ecommerce Search using Hybrid Search Techniques in Pinecone (Google Colab Notebook)</a>: Una guía práctica que muestra la implementación de búsqueda de comercio electrónico utilizando las técnicas de búsqueda híbrida de Pinecone.</li>\n<li><a href=\"https://docs.pinecone.io/docs/ecommerce-search\">Pinecone Ecommerce Search Documentation</a>: Documentación oficial de Pinecone para construir sistemas de búsqueda de comercio electrónico.</li>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/pinecone/sparse/bm25/bm25-vector-generation.ipynb\">BM25 Vector Generation using Pinecone (Google Colab Notebook)</a>: Una guía para generar vectores dispersos BM25 utilizando Pinecone.</li>\n<li><a href=\"https://github.com/pinecone-io/pinecone-text\">Pinecone Text Repository on GitHub</a>: Una colección de recursos de procesamiento de texto y generación de vectores utilizando Pinecone.</li>\n<li><a href=\"https://www.pinecone.io/learn/hybrid-search-intro/\">Introduction to Hybrid Search on Pinecone's Website</a>: Una descripción general de la búsqueda híbrida, sus beneficios y casos de uso en el contexto de las capacidades de Pinecone.</li>\n</ul>",
  "source_hash": "sha256:c8b3789c888127b9f8404365e651e80624c4177f346d2aef54a3b185e2cd138b",
  "model": "claude-sonnet-4-5-20250929",
  "generated_at": "2026-01-15T20:04:10.092630+00:00"
}