{
  "title": "PineconeとLLMを使ったEコマース向けハイブリッド検索",
  "excerpt": "従来の情報検索手法と、言語モデル(LLM)やマネージド型ベクトルデータベースのPineconeなどの機械学習モデルを組み合わせて、Eコマースアプリケーション向けの強力なハイブリッド検索システムを構築する方法を学びます。検索関連性の向上、パーソナライゼーション、ロングテールクエリの処理、インフラ管理の簡素化など、Eコマースにおけるハイブリッド検索のメリットを発見してください。",
  "content_html": "<p>関連性の高い商品を検索して見つけることは、Eコマースサイトにおいて重要な要素です。高速で正確な検索結果を提供することが、ユーザー満足度の向上とユーザーの不満の分かれ目となります。自然言語理解とベクトル検索技術の最近の進歩により、高度な検索システムがより利用しやすく効率的になり、より良いユーザー体験とコンバージョン率の向上につながっています。</p>\n\n<p>このブログ記事では、高性能なベクトル検索エンジンであるPineconeと、ドメイン固有にファインチューニングされた言語モデルを使用して、Eコマース向けのハイブリッド検索システムを実装する方法を探ります。この記事を読み終える頃には、ハイブリッド検索に関する確固たる理解だけでなく、それを実装するための実践的なステップバイステップのガイドも手に入れることができるでしょう。</p>\n\n<h2>ハイブリッド検索とは?</h2>\n\n<img src=\"/assets/images/pinecone_hybrid_index.jpg\" class=\"post-img\" alt=\"Pinecone Hybrid Index\">\n<span class=\"post-img-caption\">シンプルなPinecone Hybrid Indexの高レベルビュー</span>\n\n<p>実装に入る前に、ハイブリッド検索が何を意味するのかを簡単に理解しておきましょう。ハイブリッド検索は、従来の検索(スパースベクトル検索)とベクトル検索(デンスベクトル検索)の両方の強みを組み合わせて、幅広いドメインにわたってより良い検索パフォーマンスを実現するアプローチです。</p>\n\n<p>デンスベクトル検索は、テキストデータから高品質なベクトル埋め込みを抽出し、類似性検索を実行して関連ドキュメントを見つけます。しかし、ドメイン固有のデータセットでファインチューニングされていない場合、ドメイン外のデータでは苦戦することが多いです。</p>\n\n<p>一方、従来の検索は、単語頻度-逆文書頻度(TF-IDF)やBM25のようなスパースベクトル表現を使用し、ドメイン固有のファインチューニングを必要としません。新しいドメインを処理できる一方で、単語間の意味的関係を理解できないことと、デンス検索のようなインテリジェンスを欠いていることによって、そのパフォーマンスは制限されます。</p>\n\n<p>ハイブリッド検索は、これらを単一のシステムに組み合わせることで、両アプローチの弱点を軽減しようとし、デンスベクトル検索のパフォーマンスポテンシャルと従来の検索のゼロショット適応性を活用します。</p>\n\n<p>ハイブリッド検索の基本的な理解ができたところで、その実装に入っていきましょう。</p>\n\n<h2>ハイブリッド検索システムの構築</h2>\n\n<p>ハイブリッド検索システムを実装するために、以下のステップを説明します:</p>\n\n<ol>\n<li>ドメイン固有言語モデルの活用</li>\n<li>スパースベクトルとデンスベクトルの作成</li>\n<li>Pineconeのセットアップ</li>\n<li>ハイブリッド検索パイプラインの実装</li>\n<li>クエリの実行とパラメータのチューニング</li>\n</ol>\n\n<h3>1. ドメイン固有言語モデルの活用</h3>\n\n<p>近年、OpenAIのGPTやCohereのような大規模な事前学習済み言語モデルが、自然言語理解や生成を含むさまざまなタスクで人気を集めています。これらのモデルは、ドメイン固有のデータでファインチューニングすることで、パフォーマンスを向上させ、Eコマース商品検索のような特定のタスクに適応させることができます。</p>\n\n<p>この例では、ファインチューニングされたドメイン固有の言語モデルを使用して、商品とクエリのデンスベクトル埋め込みを生成します。ただし、他のモデルを選択したり、特定のドメインに基づいて独自のカスタム埋め込みを作成したりすることもできます。</p>\n\n<pre><code class=\"language-python\">import torch\nfrom transformers import AutoTokenizer, AutoModel\n\n# 事前学習済みのドメイン固有言語モデルをロード\nmodel_name = \"your-domain-specific-model\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModel.from_pretrained(model_name)\n\n# 商品説明のデンスベクトル埋め込みを生成\ntext = \"Nike Air Max sports shoes for men\"\ninputs = tokenizer(text, return_tensors=\"pt\")\nwith torch.no_grad():\n    outputs = model(**inputs)\n    dense_embedding = outputs.last_hidden_state.mean(dim=1).numpy()\n</code></pre>\n\n<h3>2. スパースベクトルとデンスベクトルの作成</h3>\n\n<p>ハイブリッド検索には、Eコマースデータのスパースベクトル表現とデンスベクトル表現の両方が必要です。これらのベクトルを生成する方法を説明します。</p>\n\n<h4>スパースベクトル</h4>\n\n<p>TF-IDFやBM25のようなスパースベクトル表現は、トークン化、ストップワード除去、ステミングなどの標準的なテキスト処理技術を使用して作成できます。スパースベクトルを生成する例は、語彙行列を使用して実現できます。</p>\n\n<pre><code class=\"language-python\"># この関数は商品説明リストのスパースベクトル表現を生成します\ndef generate_sparse_vectors(text):\n    '''商品説明リストのスパースベクトル表現を生成します\n\n    Args:\n        text (list): 商品説明のリスト\n\n    Returns:\n        sparse_vector (dict): インデックスと値の辞書\n    '''\n    sparse_vector = bm25.encode_queries(text)\n    return sparse_vector\n\nfrom pinecone_text.sparse import BM25Encoder\n\n# BM25エンコーダを作成してデータをフィット\nbm25 = BM25Encoder()\nbm25.fit(new_df.full_data)\n\n# スパースベクトルを作成\nsparse_vectors = []\nfor product_description in product_descriptions:\n    sparse_vectors.append(generate_sparse_vectors(text=product_description))\n</code></pre>\n\n<h4>デンスベクトル</h4>\n\n<p>デンスベクトル表現は、事前学習済みまたはカスタムのドメイン固有言語モデルを使用して生成できます。前の例では、ドメイン固有の言語モデルを使用して、商品説明のデンスベクトル埋め込みを生成しました。</p>\n\n<pre><code class=\"language-python\">def generate_dense_vector(text):\n    '''商品説明リストのデンスベクトル埋め込みを生成します\n\n    Args:\n        text (list): 商品説明のリスト\n\n    Returns:\n        dense_embedding (np.array): デンスベクトル埋め込みのnumpy配列\n    '''\n    # テキストをトークン化してPyTorchテンソルに変換\n    inputs = tokenizer(text, return_tensors=\"pt\")\n    # 事前学習済みモデルで埋め込みを生成\n    with torch.no_grad():\n        outputs = model(**inputs)\n        dense_vector = outputs.last_hidden_state.mean(dim=1).numpy()\n    return dense_vector\n\n# 商品説明リストのデンスベクトル埋め込みを生成\ndense_vectors = []\nfor product_description in product_descriptions:\n    dense_vectors.append(generate_dense_vector(text=product_description))\n</code></pre>\n\n<h3>3. Pineconeのセットアップ</h3>\n\n<p>Pineconeは、ハイブリッド検索をサポートする高性能なベクトル検索エンジンです。スパースベクトルとデンスベクトルの両方に対して単一のインデックスを作成でき、異なるデータモダリティにわたる検索クエリをシームレスに処理します。</p>\n\n<p>Pineconeを使用するには、アカウントにサインアップし、Pineconeクライアントをインストールし、APIキーと環境を設定する必要があります。</p>\n\n<pre><code class=\"language-python\"># Pineconeハイブリッド検索インデックスを作成\nimport pinecone\n\npinecone.init(\n    api_key=\"YOUR_API_KEY\",  # app.pinecone.io\n    environment=\"YOUR_ENV\"  # コンソールのAPIキーの横にあります\n)\n\n# Pineconeハイブリッド検索インデックスを作成\nindex_name = \"ecommerce-hybrid-search\"\npinecone.create_index(\n    index_name = index_name,\n    dimension = MODEL_DIMENSION,  # デンスモデルの次元数\n    metric = \"dotproduct\"\n)\n# インデックスに接続\nindex = pinecone.Index(index_name=index_name)\n# インデックス統計を表示\nindex.describe_index_stats()\n</code></pre>\n\n<h3>4. ハイブリッド検索パイプラインの実装</h3>\n\n<p>スパースベクトルとデンスベクトルが生成され、Pineconeがセットアップされたので、ハイブリッド検索パイプラインを構築できます。このパイプラインには以下のステップが含まれます:</p>\n\n<ol>\n<li>Pineconeインデックスへの商品データの追加</li>\n<li>スパースベクトルとデンスベクトルの両方を使用した結果の取得</li>\n</ol>\n\n<pre><code class=\"language-python\">def add_product_data_to_index(product_ids, sparse_vectors, dense_vectors, metadata=None):\n    \"\"\"Pineconeインデックスに商品データをアップサートします。\n\n    Args:\n        product_ids (`list` of `str`): 商品ID。\n        sparse_vectors (`list` of `list` of `float`): スパースベクトル。\n        dense_vectors (`list` of `list` of `float`): デンスベクトル。\n        metadata (`list` of `list` of `str`): オプションのメタデータ。\n\n    Returns:\n        None\n    \"\"\"\n    batch_size = 32\n\n    # 商品IDをバッチでループ処理します。\n    for i in range(0, len(product_ids), batch_size):\n        i_end = min(i + batch_size, len(product_ids))\n        ids = product_ids[i:i_end]\n        sparse_batch = sparse_vectors[i:i_end]\n        dense_batch = dense_vectors[i:i_end]\n        meta_batch = metadata[i:i_end] if metadata else []\n\n        vectors = []\n        for _id, sparse, dense, meta in zip(ids, sparse_batch, dense_batch, meta_batch):\n            vectors.append({\n                'id': _id,\n                'sparse_values': sparse,\n                'values': dense,\n                'metadata': meta\n            })\n\n        # Pineconeインデックスにベクトルをアップサート。\n        index.upsert(vectors=vectors)\n\nadd_product_data_to_index(product_ids, sparse_vectors, dense_vectors)\n</code></pre>\n\n<p>データがインデックス化されたので、ハイブリッド検索クエリを実行できます。</p>\n\n<h3>5. クエリの実行とパラメータのチューニング</h3>\n\n<img src=\"/assets/images/pinecone_hybrid_query.jpg\" class=\"post-img\" alt=\"Pinecone Hybrid Query\">\n<span class=\"post-img-caption\">シンプルなPinecone Hybrid Queryの高レベルビュー</span>\n\n<p>ハイブリッド検索クエリを実行するために、クエリ、トップ結果の数、そしてデンスベクトル検索スコアとスパースベクトル検索スコアの間の重み付けを制御するalphaパラメータを受け取る関数を作成します。</p>\n\n<pre><code class=\"language-python\">def hybrid_scale(dense, sparse, alpha: float):\n    \"\"\"凸結合を使用したハイブリッドベクトルスケーリング\n\n    alpha * dense + (1 - alpha) * sparse\n\n    Args:\n        dense: 浮動小数点数の配列\n        sparse: `indices`と`values`の辞書\n        alpha: 0と1の間の浮動小数点数。0はスパースのみ、\n               1はデンスのみ\n    \"\"\"\n    if alpha < 0 or alpha > 1:\n        raise ValueError(\"Alphaは0と1の間でなければなりません\")\n    # スパースベクトルとデンスベクトルをスケーリングしてハイブリッド検索ベクトルを作成\n    hsparse = {\n        'indices': sparse['indices'],\n        'values':  [v * (1 - alpha) for v in sparse['values']]\n    }\n    hdense = [v * alpha for v in dense]\n    return hdense, hsparse\n\ndef search_products(query, top_k=10, alpha=0.5):\n    # スパースクエリベクトルを生成\n    sparse_query_vector = generate_sparse_vector(query)\n\n    # デンスクエリベクトルを生成\n    dense_query_vector = generate_dense_vector(query)\n\n    # ハイブリッドクエリベクトルを計算\n    dense_query_vector, sparse_query_vector = hybrid_scale(dense_query_vector, sparse_query_vector, alpha)\n\n    # Pineconeを使用して商品を検索\n    results = index.query(\n        vector=dense_query_vector,\n        sparse_vector=sparse_query_vector,\n        top_k=top_k\n    )\n\n    return results\n</code></pre>\n\n<p>この関数を使用して、Eコマースデータセット内の関連商品を検索できます。</p>\n\n<pre><code class=\"language-python\">query = \"running shoes for women\"\nresults = search_products(query, top_k=5)\n\nfor result in results:\n    print(result['id'], result['metadata']['product_name'], result['score'])\n</code></pre>\n\n<p>alphaパラメータの異なる値を試すことで、特定のドメインに対してスパースベクトル検索とデンスベクトル検索の最適なバランスを見つけることができます。</p>\n\n<h2>まとめ</h2>\n\n<p>このブログ記事では、Pineconeとドメイン固有の言語モデルを使用して、Eコマース向けのハイブリッド検索システムを構築する方法を示しました。ハイブリッド検索により、従来の検索とベクトル検索の両方の強みを組み合わせ、多様なドメインにわたって検索パフォーマンスと適応性を向上させることができます。</p>\n\n<p>この記事で提供されたステップとコードスニペットに従うことで、EコマースサイトのWebサイトの特定の要件に合わせた独自のハイブリッド検索システムを実装できます。今すぐPineconeの探索を始めて、Eコマース検索体験を向上させましょう!</p>\n\n<h2>参考文献</h2>\n\n<ul>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/search/hybrid-search/ecommerce-search/ecommerce-search.ipynb\">Ecommerce Search using Hybrid Search Techniques in Pinecone (Google Colab Notebook)</a>: Pineconeのハイブリッド検索技術を使用したEコマース検索の実装を紹介する実践的なガイド。</li>\n<li><a href=\"https://docs.pinecone.io/docs/ecommerce-search\">Pinecone Ecommerce Search Documentation</a>: Eコマース検索システム構築のための公式Pineconeドキュメント。</li>\n<li><a href=\"https://colab.research.google.com/github/pinecone-io/examples/blob/master/pinecone/sparse/bm25/bm25-vector-generation.ipynb\">BM25 Vector Generation using Pinecone (Google Colab Notebook)</a>: Pineconeを使用してBM25スパースベクトルを生成するためのガイド。</li>\n<li><a href=\"https://github.com/pinecone-io/pinecone-text\">Pinecone Text Repository on GitHub</a>: Pineconeを使用したテキスト処理とベクトル生成リソースのコレクション。</li>\n<li><a href=\"https://www.pinecone.io/learn/hybrid-search-intro/\">Introduction to Hybrid Search on Pinecone's Website</a>: Pineconeの機能におけるハイブリッド検索、そのメリット、ユースケースの概要。</li>\n</ul>",
  "source_hash": "sha256:14601d746f122e4e17ae78f475838ea1679e3865f9f52de9e7fc610d6b5fb139",
  "model": "claude-sonnet-4-5-20250929",
  "generated_at": "2026-01-01T23:59:11.065723+00:00"
}